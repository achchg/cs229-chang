{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "954d3893",
   "metadata": {},
   "source": [
    "## MedMnist Dataset\n",
    "\n",
    "Followed example notebook from MedMNIST here:\n",
    "https://github.com/MedMNIST/MedMNIST/blob/main/examples/getting_started.ipynb\n",
    "https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9f2eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import autograd, optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "cudnn.benchmark = True\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a0425d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import medmnist\n",
    "from medmnist import INFO, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "238dee60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MedMNIST v2.0.2 @ https://github.com/MedMNIST/MedMNIST/\n"
     ]
    }
   ],
   "source": [
    "print(f\"MedMNIST v{medmnist.__version__} @ {medmnist.HOMEPAGE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0e56df",
   "metadata": {},
   "source": [
    "Check what are in the INFO:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfd0389b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(INFO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "601c0555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['pathmnist', 'chestmnist', 'dermamnist', 'octmnist', 'pneumoniamnist', 'retinamnist', 'breastmnist', 'bloodmnist', 'tissuemnist', 'organamnist', 'organcmnist', 'organsmnist', 'organmnist3d', 'nodulemnist3d', 'adrenalmnist3d', 'fracturemnist3d', 'vesselmnist3d', 'synapsemnist3d']) 18\n"
     ]
    }
   ],
   "source": [
    "print(INFO.keys(), len(INFO.keys()))\n",
    "# Looks like 18 datasets available, 6 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c36d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'python_class': 'PathMNIST',\n",
       " 'description': 'The PathMNIST is based on a prior study for predicting survival from colorectal cancer histology slides, providing a dataset (NCT-CRC-HE-100K) of 100,000 non-overlapping image patches from hematoxylin & eosin stained histological images, and a test dataset (CRC-VAL-HE-7K) of 7,180 image patches from a different clinical center. The dataset is comprised of 9 types of tissues, resulting in a multi-class classification task. We resize the source images of 3×224×224 into 3×28×28, and split NCT-CRC-HE-100K into training and validation set with a ratio of 9:1. The CRC-VAL-HE-7K is treated as the test set.',\n",
       " 'url': 'https://zenodo.org/record/5208230/files/pathmnist.npz?download=1',\n",
       " 'MD5': 'a8b06965200029087d5bd730944a56c1',\n",
       " 'task': 'multi-class',\n",
       " 'label': {'0': 'adipose',\n",
       "  '1': 'background',\n",
       "  '2': 'debris',\n",
       "  '3': 'lymphocytes',\n",
       "  '4': 'mucus',\n",
       "  '5': 'smooth muscle',\n",
       "  '6': 'normal colon mucosa',\n",
       "  '7': 'cancer-associated stroma',\n",
       "  '8': 'colorectal adenocarcinoma epithelium'},\n",
       " 'n_channels': 3,\n",
       " 'n_samples': {'train': 89996, 'val': 10004, 'test': 7180},\n",
       " 'license': 'CC BY 4.0'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INFO['pathmnist']\n",
    "# Print out one of the dataset to observe the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f431caa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_flag = 'pathmnist'\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 3\n",
    "BATCH_SIZE = 128\n",
    "lr = 0.001\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff48013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /Users/chi-hsuanchang/.medmnist/pathmnist.npz\n",
      "Using downloaded and verified file: /Users/chi-hsuanchang/.medmnist/pathmnist.npz\n",
      "Using downloaded and verified file: /Users/chi-hsuanchang/.medmnist/pathmnist.npz\n"
     ]
    }
   ],
   "source": [
    "# preprocessing\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n",
    "\n",
    "# load the data\n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
    "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
    "\n",
    "pil_dataset = DataClass(split='train', download=download)\n",
    "\n",
    "# encapsulate data into dataloader form\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                               batch_size=BATCH_SIZE, \n",
    "                               shuffle=True)\n",
    "\n",
    "train_loader_at_eval = DataLoader(dataset=train_dataset, \n",
    "                                       batch_size=2*BATCH_SIZE, \n",
    "                                       shuffle=False)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                              batch_size=2*BATCH_SIZE, \n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48271e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=56x56>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualization\n",
    "train_dataset.montage(length=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bde658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# print(inspect.getsource(medmnist.dataset.MedMNIST2D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4711cca5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(inspect.getsource(nn.Conv2d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b746223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a simple CNN model\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels=16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64 * 4 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        outputs = self.fc(x)\n",
    "        return outputs\n",
    "\n",
    "model = Net(in_channels=n_channels, num_classes=n_classes)\n",
    "    \n",
    "# define loss function and optimizer\n",
    "if task == \"multi-label, binary-class\":\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970fb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim , num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        outputs = self.fc(x)\n",
    "        return outputs\n",
    "\n",
    "model = LogisticRegression(input_dim = 2352, num_classes=n_classes)\n",
    "    \n",
    "# define loss function and optimizer\n",
    "if task == \"multi-label, binary-class\":\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa20566",
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)\n",
    "    print(inputs.view(inputs.size(0), -1).shape)\n",
    "    print(inputs.view(inputs.size(0), -1))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652d7361",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c644031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, targets in tqdm(train_loader):\n",
    "        # forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.float32)\n",
    "            loss = criterion(outputs, targets)\n",
    "        else:\n",
    "            targets = targets.squeeze().long()\n",
    "            loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a693b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation\n",
    "\n",
    "def test(split):\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([])\n",
    "    y_score = torch.tensor([])\n",
    "    \n",
    "    data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "            else:\n",
    "                targets = targets.squeeze().long()\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "\n",
    "        y_true = y_true.numpy()\n",
    "        y_score = y_score.detach().numpy()\n",
    "        \n",
    "        evaluator = Evaluator(data_flag, split)\n",
    "        metrics = evaluator.evaluate(y_score)\n",
    "    \n",
    "        print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
    "\n",
    "        \n",
    "print('==> Evaluating ...')\n",
    "test('train')\n",
    "test('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697db57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/medmnist_experiment_2-logistic-regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a4fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to show an image\n",
    "# (used in the `plot_classes_preds` function below)\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9da2ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = vutils.make_grid(images)\n",
    "\n",
    "# show images\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# write to tensorboard\n",
    "writer.add_image('medmnist_mnist_images', img_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3660d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, images)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ee650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, class_names):\n",
    "    \"\"\"\n",
    "    Returns a matplotlib figure containing the plotted confusion matrix.\n",
    "\n",
    "    Args:\n",
    "      cm (array, shape = [n, n]): a confusion matrix of integer classes\n",
    "      class_names (array, shape = [n]): String names of the integer classes\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names, rotation=45)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "\n",
    "    # Compute the labels from the normalized confusion matrix.\n",
    "    labels = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "    # Use white text if squares are dark; otherwise black.\n",
    "    threshold = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        color = \"white\" if cm[i, j] > threshold else \"black\"\n",
    "        plt.text(j, i, labels[i, j], horizontalalignment=\"center\", color=color)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0bcf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Define the basic TensorBoard callback.\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local_gan",
   "language": "python",
   "name": "local_gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
